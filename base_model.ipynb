{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /trinity/home/thomgeo/micromamba/envs/open_eraa/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import powerplantmatching as pm\n",
    "import pypsa\n",
    "import pycountry\n",
    "import os \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inflows(inflows):\n",
    "\n",
    "    base_year_hydro = pd.Series(\n",
    "    inflows.index.levels[3].astype(int), \n",
    "    inflows.index.levels[3]).subtract(year).abs().idxmin()\n",
    "\n",
    "    inflows = inflows.loc[:, str(climate_year),:, base_year_hydro,:]\n",
    "    \n",
    "    inflow_grouper = pd.Series([\"hydro\", \"ROR\", \"PHS Open\", \"pondage\"],inflows.index.levels[2])\n",
    "    \n",
    "    #inflow_grouper.to_csv('commodity_filtered.csv', index=False)\n",
    "\n",
    "    inflows = inflows.unstack(2).groupby(inflow_grouper, axis=1).sum().multiply(1) \n",
    "    inflows = inflows.unstack(0).stack(0)\n",
    "    \n",
    "    inflows.index = [\" \".join(i) for i in inflows.index]\n",
    "    \n",
    "    inflows = inflows.T\n",
    "    \n",
    "    inflows.index = snapshots  \n",
    "   \n",
    "    return inflows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_existing_storage():  \n",
    " \n",
    "    storage = capacity.loc[[\"PHS\", \"reservoir\", \"battery\"]].unstack().reset_index().copy()\n",
    "    storage.columns = [\"bus\", \"carrier\", \"p_nom\"]\n",
    "    storage.index = storage.bus + \" \" + storage.carrier\n",
    "\n",
    "    p_min_pu = capacity.loc[[\"PHS (pumping)\", \"reservoir (pumping)\",]].div(capacity.loc[[\"PHS\", \"reservoir\"]].add(1e-5).values)\n",
    "    p_min_pu.index = [\"PHS\", \"reservoir\"]\n",
    "\n",
    "    storage[\"p_min_pu\"] = (\n",
    "        p_min_pu.unstack()\n",
    "        .reindex(pd.MultiIndex.from_arrays([storage.bus, storage.carrier]))\n",
    "    ).values\n",
    "\n",
    "    storage.loc[storage.carrier==\"battery\", \"p_min_pu\"] = -1\n",
    "\n",
    "    storage = storage[storage.p_nom >0]\n",
    "\n",
    "    storage_inflows = inflows[storage.loc[storage.carrier==\"reservoir\"].index]\n",
    "\n",
    "    storage_capacity_raw = pd.read_excel(excel_file, sheet, index_col=1, header=28).dropna(how=\"all\", axis=1)\n",
    "\n",
    "    storage_capacity= storage_capacity_raw.groupby(\n",
    "        [\"ROR\", \"reservoir\", \"reservoir\", \"PHS\", \"battery\"]\n",
    "    ).sum()\n",
    "\n",
    "    storage[\"max_hours\"] = storage_capacity.unstack().reindex(\n",
    "        pd.MultiIndex.from_arrays(\n",
    "            [storage.bus, storage.carrier]  \n",
    "        )\n",
    "    ).div(\n",
    "        storage.p_nom.values\n",
    "    ).values\n",
    "\n",
    "    map_storage = pd.Series( [\"battery inverter\", \"PHS\", \"hydro\"], [\"battery\", \"PHS\", \"reservoir\"])\n",
    "\n",
    "    storage[\"efficiency_store\"] = technology_data.loc[:, \"efficiency\", :].reindex(storage.carrier.map(map_storage)).value.values\n",
    "\n",
    "    n.madd(\n",
    "        \"StorageUnit\",\n",
    "        storage.index,\n",
    "        **storage,\n",
    "        inflow=storage_inflows,\n",
    "        invest_status = \"existing\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_existing_storage(all_c):  \n",
    " \n",
    " \n",
    "    hydro = pd.read_csv(\"data/Dashboard_raw_data/Hydro additional information.csv\",header=0)\n",
    "    \n",
    "    all_c = all_c.reset_index(name=\"Value\")\n",
    "    \n",
    "    closest_year = all_c.loc[(all_c['Target year'] - base_year).abs().idxmin(), 'Target year']\n",
    "\n",
    "    all_cy = all_c[all_c['Target year'] == closest_year]\n",
    "    \n",
    "    #all_cy.to_csv('all_cy.csv', index=False)\n",
    "\n",
    "    all_cdata = (all_cy\n",
    "      .pivot(index=\"Technology\", columns=\"Market_Node\", values=all_cy.columns[-1]) \n",
    "      )\n",
    "\n",
    "    storage = all_cdata.loc[[\"PHS\",\"PHS Open\",\"hydro\",\"pondage\",\"battery\"]].unstack().reset_index().copy()\n",
    "    storage.columns = [\"bus\", \"carrier\", \"p_nom\"]\n",
    "    storage.index = storage.bus + \" \" + storage.carrier\n",
    "\n",
    "    hydro = hydro[hydro.apply(lambda row: row.astype(str).str.contains(\"ERAA 2025 pre-CfE\").any(), axis=1)]\n",
    "    #hydro.to_csv('hydro.csv', index=False)\n",
    "\n",
    "    \n",
    "    target_year = hydro.loc[hydro[\"TARGET_YEAR\"].sub(base_year).abs().idxmin(), \"TARGET_YEAR\"]\n",
    "    hydro_y = hydro[hydro[\"TARGET_YEAR\"] == target_year]\n",
    "    \n",
    "    #hydro_y.to_csv('hydroyear.csv', index=False)\n",
    "    \n",
    "    hydro_pump = -(\n",
    "    hydro_y.loc[\n",
    "        hydro_y[\"PEMMDB_PLANT_TYPE\"].isin([\"Closed loop pumping\", \"Open loop pumping\"])\n",
    "    ]\n",
    "    .pivot(index=\"PEMMDB_PLANT_TYPE\", columns=\"MARKET_NODE\", values=\"MAX PUMPING CAP (MW)\")\n",
    "    .fillna(0)\n",
    "    .rename(index={\n",
    "        \"Closed loop pumping\": \"PHS\",\n",
    "        \"Open loop pumping\": \"PHS Open\"\n",
    "    })\n",
    ")\n",
    "\n",
    "    hydro_pump=hydro_pump.drop(columns=[\"UA00\"], errors='ignore').loc[:, (hydro_pump != 0).any(axis=0)]\n",
    "    #hydro_pump.to_csv('hydrostorage.csv', index=False)      \n",
    "\n",
    "    hydro_cap=all_cdata.loc[all_cdata.index.isin([\"PHS\", \"PHS Open\"])]\n",
    "    \n",
    "    #hydro_cap.loc[:, hydro_cap.notna().any(axis=0)].to_csv('hydrocapacity.csv', index=False)\n",
    "\n",
    "    p_min_pu = hydro_pump.div(hydro_cap.loc[:, hydro_cap.notna().any(axis=0)].add(1e-5).values).fillna(0)\n",
    "    p_min_pu.index = [\"PHS\", \"PHS Open\"]\n",
    "    \n",
    "    p_min_pu.to_csv('p_min_pu.csv', index=False)\n",
    "    \n",
    "    valid_countries = p_min_pu.columns[(p_min_pu != 0).any(axis=0)]\n",
    "    p_min_pu_filtered = p_min_pu[valid_countries]\n",
    "    p_min_pu_stacked = p_min_pu_filtered.stack().fillna(0)  # MultiIndex: (carrier, bus)\n",
    "    storage_index = pd.MultiIndex.from_arrays([storage.carrier, storage.bus])\n",
    "    storage[\"p_min_pu\"] = p_min_pu_stacked.reindex(storage_index).values \n",
    "    \n",
    "    #storage.to_csv('storage.csv', index=False)\n",
    "\n",
    "    storage.loc[storage.carrier==\"battery\", \"p_min_pu\"] = -1\n",
    "    storage.loc[storage.carrier==\"hydro\", \"p_min_pu\"] = 0\n",
    "    storage.loc[storage.carrier==\"pondage\", \"p_min_pu\"] = 0\n",
    "\n",
    "    storage = storage[storage.p_nom >0]\n",
    "    \n",
    "    #storage.to_csv('storage.csv', index=False)\n",
    "    \n",
    "    storage_inflows = inflows[storage.loc[storage.carrier==\"PHS Open\"].index]\n",
    "    \n",
    "    #storage_inflows .to_csv('storage_inflows0.csv', index=False)\n",
    "    \n",
    "    storage_inflows = pd.concat([storage_inflows,inflows[storage.loc[storage.carrier == \"hydro\"].index]],axis=1)\n",
    "    storage_inflows = pd.concat([storage_inflows,inflows[storage.loc[storage.carrier == \"pondage\"].index]],axis=1)\n",
    "    \n",
    "    storage_inflows.to_csv('storage_inflows.csv', index=False)\n",
    "    \n",
    "    hydro_stored = 1000000*(hydro_y.loc[hydro_y[\"PEMMDB_PLANT_TYPE\"].isin([\"Closed loop pumping\", \"Open loop pumping\", \"Reservoir\", \"Pondage\"])]\n",
    "      .pivot(index=\"PEMMDB_PLANT_TYPE\", columns=\"MARKET_NODE\", values=\"Storage Capacity [TWh]\")\n",
    "      .fillna(0)\n",
    "      .rename(index={\n",
    "          \"Closed loop pumping\": \"PHS\",\n",
    "          \"Open loop pumping\": \"PHS Open\",\n",
    "          \"Reservoir\": \"hydro\",\n",
    "          \"Pondage\": \"pondage\"                    \n",
    "      })\n",
    ")       \n",
    "\n",
    "    print(hydro_stored)\n",
    "        \n",
    "    battery = pd.read_csv(\"data/Dashboard_raw_data/Batteries additional information.csv\",header=0)\n",
    "    battery = battery[battery.apply(lambda row: row.astype(str).str.contains(\"ERAA 2025 pre-CfE\").any(), axis=1)]\n",
    "    battery.to_csv('battery.csv', index=False)\n",
    "    \n",
    "    battery_y = battery[battery[\"TARGET_YEAR\"] == base_year]\n",
    "    \n",
    "    battery_y.to_csv('battery_y.csv', index=False)\n",
    "    \n",
    "    battery_by_node = battery_y.groupby(\"MARKET_NODE\")[\"STORAGE CAPACITY (MWh)\"].sum().reset_index()\n",
    "    \n",
    "    battery_by_node.to_csv('battery_y.csv', index=False)\n",
    "    battery_by_node[\"Technology\"] = \"battery\"\n",
    "    battery_pivot = battery_by_node.pivot(index=\"Technology\", columns=\"MARKET_NODE\", values=\"STORAGE CAPACITY (MWh)\").fillna(0)\n",
    "    \n",
    "    battery_pivot.to_csv('battery_pivot.csv', index=False)\n",
    "    \n",
    "    storage_capacity=pd.concat([hydro_stored, battery_pivot])\n",
    "    \n",
    "    storage_capacity.to_csv('storage_capacity.csv', index=False)\n",
    "      \n",
    "    valid_countries = storage_capacity.columns[(storage_capacity != 0).any(axis=0)]\n",
    "    stored_filtered = storage_capacity[valid_countries]\n",
    "        \n",
    "    stored_stacked = stored_filtered.stack() \n",
    "    \n",
    "    storage_index = pd.MultiIndex.from_arrays([storage.carrier, storage.bus])\n",
    "    \n",
    "    #Data in #.## TWh, so 5000 MWh as minimum\n",
    "    storage[\"max_hours\"] = stored_stacked.reindex(storage_index).clip(lower=5000).div(storage.p_nom.values).values \n",
    "       \n",
    "    map_storage = pd.Series( [\"battery inverter\", \"PHS\", \"hydro\",\"hydro\",\"hydro\"], [\"battery\", \"PHS\", \"PHS Open\",\"hydro\",\"pondage\"])\n",
    "\n",
    "    storage[\"efficiency_store\"] = technology_data.loc[:, \"efficiency\", :].reindex(storage.carrier.map(map_storage)).value.values\n",
    "    \n",
    "    storage.to_csv('storage.csv', index=False)\n",
    "\n",
    "    n.add(\n",
    "        \"StorageUnit\",\n",
    "        storage.index,\n",
    "        **storage,\n",
    "        inflow=storage_inflows,\n",
    "        invest_status = \"existing\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_commodity_prices(commodity_prices):\n",
    "    \n",
    "    fuels = [\"co2\", \"gas\", \"coal\", \"oil\",\"lignite\", \"hydrogen\", \"nuclear\"]\n",
    "    C02= [57,0, 94, 0,101, 0, 85.3] #gas, co2, coal, hydrogen, lignite, nuclear, oil\n",
    "        \n",
    "    def assign_fuel_group(fuel_name):\n",
    "      fuel_name_lower = str(fuel_name).lower()\n",
    "      for f in fuels:\n",
    "          if f.lower() in fuel_name_lower:\n",
    "              return \"CCGT\" if f.lower() == \"gas\" else f\n",
    "      return None\n",
    "    \n",
    "    commodity_prices[\"Fuel\"] = commodity_prices[\"Fuel\"].apply(assign_fuel_group)  \n",
    "    \n",
    "    commodity_prices_filtered = commodity_prices[commodity_prices[\"Fuel\"].notna()]\n",
    "    \n",
    "    commodity_prices[\"Fuel\"] = commodity_prices[\"Fuel\"].replace(\"gas\", \"CCGT\")\n",
    "    \n",
    "    #commodity_prices.to_csv('commodity_filteredFuel.csv', index=False)\n",
    "    \n",
    "    commodity_prices = (\n",
    "    commodity_prices_filtered\n",
    "    .groupby([\"Year\", \"Fuel\"], as_index=False)[\"Value\"]\n",
    "    .mean()\n",
    "    )\n",
    "\n",
    "     \n",
    "    commodity_prices = commodity_prices.pivot(index=\"Fuel\", columns=\"Year\", values=\"Value\").reset_index()\n",
    "     \n",
    "    commodity_prices[\"CO2\"] = C02\n",
    "     \n",
    "    #commodity_prices.to_csv('commodity_column.csv', index=False) \n",
    "       \n",
    "    #commodity_prices_filtered.to_csv('commodity_filtered.csv', index=False)  \n",
    "    \n",
    "    commodity_prices = commodity_prices.set_index(\"Fuel\")\n",
    "    \n",
    "    commodity_prices = commodity_prices.apply(pd.to_numeric, errors=\"coerce\")\n",
    "      \n",
    "    converter = pd.DataFrame(3.6 , commodity_prices.index, commodity_prices.columns)\n",
    "    converter[\"CO2\"] = 3.6/1000 \n",
    "    converter.loc[\"co2\"] = 1\n",
    "\n",
    "    commodity_prices = converter*commodity_prices\n",
    "\n",
    "\n",
    "    to_add = commodity_prices.reindex([\"CCGT\", \"CCGT\"])\n",
    "    to_add.index = [\"OCGT\", \"biomass\"]\n",
    "    #to_add.loc[[\"other\"]] = 0\n",
    "    to_add.loc[[\"biomass\"]] = biomass_price\n",
    "    to_add.loc[[\"biomass\"], \"CO2\"] = 0\n",
    "    commodity_prices = pd.concat([commodity_prices, to_add])\n",
    "    commodity_prices.to_csv('commodity_prices.csv', index=False)\n",
    "    \n",
    "    return commodity_prices\n",
    "\n",
    "def add_renewables():\n",
    "       \n",
    "    res = capacity.loc[[\"CSP\",\"CSPS\",\"onwind\",\"offwind\",\"PVfixed\",\"PVIroof\", \"PVRroof\", \"PVtrack\",\"ROR\"]].unstack().copy()\n",
    "    res = res.reset_index()\n",
    "    res.columns = [\"bus\", \"carrier\", \"p_nom\"]\n",
    "    res.index = res.bus + \" \" + res.carrier\n",
    "\n",
    "    res = res[res.p_nom>0]\n",
    "    \n",
    "    vre=[\"CSP\",\"CSP-stor\",\"onwind\",\"offwind\",\"solar-fix\",\"solar-rsd\", \"solar-ind\",\"solar-track\"]\n",
    "   \n",
    "    p_max_pu = pd.concat(\n",
    "        [pd.read_hdf(snakemake.input.res_profile, tech).loc[:, \"WS{:02}\".format(climate_year), str(base_year), :] for tech in vre],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    #print(\"found RES in res_profile\")\n",
    "    \n",
    "    p_max_pu.columns = vre\n",
    "    p_max_pu = p_max_pu.unstack(0).stack(0)\n",
    "    p_max_pu.index = [\" \".join(i) for i in p_max_pu.index]\n",
    "    p_max_pu.columns = snapshots\n",
    "    p_max_pu = p_max_pu.T\n",
    "\n",
    "    #print(len(inflows[res.filter(like=\"ROR\", axis=0).index]))\n",
    "    #print(len(res.filter(like=\"ROR\", axis=0).p_nom))\n",
    "\n",
    "    p_max_pu = pd.concat(\n",
    "        [p_max_pu, inflows[res.filter(like=\"ROR\", axis=0).index].div(res.filter(like=\"ROR\", axis=0).p_nom).clip(upper=1)],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    #p_max_pu = pd.concat(\n",
    "    #    [p_max_pu, inflows[res.filter(like=\"pondage\", axis=0).index].div(res.filter(like=\"pondage\", axis=0).p_nom)],\n",
    "    #    axis=1\n",
    "    #)\n",
    "    \n",
    "    p_max_pu[res.index].to_csv('res.csv', index=False)\n",
    "\n",
    "    n.add(\n",
    "        \"Generator\",\n",
    "        res.index,\n",
    "        **res,\n",
    "        p_max_pu = p_max_pu[res.index],\n",
    "        invest_status=\"policy\"\n",
    "    )\n",
    "    \n",
    "def add_dispatchables():\n",
    "         \n",
    "    plants = dispatchable_plants.query(\"(entry <= @year) & exit > @year\")\n",
    "\n",
    "    plants[\"marginal_cost\"] = (\n",
    "        commodity_prices\n",
    "        .reindex(plants.carrier)[base_year].div(\n",
    "            plants.efficiency.values,\n",
    "        ).add(\n",
    "            (\n",
    "                commodity_prices.reindex(\n",
    "                    plants.carrier)[\"CO2\"]\n",
    "                .multiply(\n",
    "                    commodity_prices.loc[\"co2\", base_year]\n",
    "                )\n",
    "            )\n",
    "        ).add(plants.var_om.values).values\n",
    "    )\n",
    "    #plants.loc[:, \"p_min_pu\"] = 0\n",
    "    plants.loc[:, \"committable\"]= True\n",
    "    #plants.loc[:, \"up_time_before\"] = 2\n",
    "    #plants.loc[:, \"down_time_before\"] = 100\n",
    "    \n",
    "    \n",
    "    plants.to_csv('plants.csv', index=False)\n",
    "    n.add(\n",
    "        \"Generator\",\n",
    "        plants.index,\n",
    "        **plants,\n",
    "    )\n",
    "\n",
    "def group_luxembourg(demand, links):\n",
    "    \n",
    "    demand_grouper = pd.Series(demand.columns, demand.columns)\n",
    "    demand_grouper.loc[demand_grouper.index.str[:2] == \"LU\"] = \"LUG1\"\n",
    "    demand = demand.groupby(demand_grouper, axis=1).sum()\n",
    "\n",
    "    links.loc[links.bus0.str[:2] == \"LU\", \"bus0\"] = \"LUG1\"\n",
    "    links.loc[links.bus1.str[:2] == \"LU\", \"bus1\"] = \"LUG1\"\n",
    "    \n",
    "    return demand, links\n",
    "\n",
    "def add_dsr():\n",
    "    \n",
    "    \n",
    "    dsr=pd.read_hdf(snakemake.input.dsr)\n",
    "    \n",
    "    dsr = dsr.loc[base_year, :]\n",
    "    \n",
    "    dsr.unstack(1).columns = [\"bus\", \"p_nom\", \"marginal_cost\"]\n",
    "    \n",
    "    dsr=dsr.drop(columns=[\"hours\",\"TARGET_YEAR\"])\n",
    "    \n",
    "    dsr[\"carrier\"] = \"DSR\"\n",
    "    \n",
    "    dsr.index = [f\"{bus} {carrier} {i}\" for i, (bus, carrier) in enumerate(zip(dsr.bus, dsr.carrier))]\n",
    "\n",
    "    \n",
    "#    dsr.index = [dsr.bus + \" \" + dsr.carrier + \" \".join(i) for i in len(inflows.index)] \n",
    "    \n",
    "    dsr.to_csv('DSR.csv', index=False)\n",
    "    \n",
    "    print(dsr.index)\n",
    "\n",
    "    n.add(\n",
    "        \"Generator\",\n",
    "        dsr.index,\n",
    "        **dsr,\n",
    "        invest_status = \"existing\"\n",
    "    )\n",
    "    \n",
    "\n",
    "def set_investment_bounds():\n",
    "    \n",
    "    n.generators.loc[n.generators.invest_status == \"policy\", \"p_nom_max\"] = n.generators.loc[n.generators.invest_status == \"policy\", \"p_nom\"]\n",
    "    n.generators.loc[n.generators.invest_status == \"policy\", \"p_nom_min\"] = n.generators.loc[n.generators.invest_status == \"policy\", \"p_nom\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_prices_raw = pd.read_csv(\"data/Dashboard_raw_data/Commodity Prices.csv\",header=0)\n",
    "\n",
    "all_cap=pd.read_hdf(\"resources/all_capacities.h5\")\n",
    "\n",
    "year = int(2030)\n",
    "climate_year = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2028, 2035)\n",
    "\n",
    "#save_path = snakemake.output.network\n",
    "\n",
    "biomass_price = 7# snakemake.config[\"biomass_price\"]\n",
    "\n",
    "dispatchable = [\"CCGT\", \"OCGT\", 'biomass', 'coal', 'lignite', 'nuclear','oil','hydrogen']\n",
    "distributed_resources = [\"onwind\", \"offwind\", \"CSP\",\"solar\", \"battery\"]\n",
    "\n",
    "technologies_for_investment = [\"OCGT\", \"CCGT\"]\n",
    "\n",
    "inflows_raw = pd.read_hdf(\"resources/inflow.h5\", \"inflow\")\n",
    "\n",
    "snapshots = pd.date_range(start=\"2010-01-01\", freq=\"h\", periods=8760)#.strftime('%m-%d %H:%M:%S')\n",
    "\n",
    "base_year = pd.Series(\n",
    "all_cap.index.levels[0].astype(int), \n",
    "all_cap.index.levels[0]).subtract(year).abs().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_data = pd.read_csv(\"technology-data/outputs/costs_2025.csv\", index_col=[0,1])\n",
    "demand = pd.read_hdf(\"resources/demand.h5\")\n",
    "\n",
    "demand = demand.loc[:, \"WS{:02}\".format(climate_year), :, str(base_year), :].unstack(1)\n",
    "demand.index = snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_hdf(\"resources/ntcs.h5\", \"p_nom\")\n",
    "links = links[base_year].unstack(1)\n",
    "links = links.iloc[:len(snapshots)]\n",
    "\n",
    "links_p_max_pu = pd.read_hdf(\"resources/ntcs.h5\", \"p_max_pu\")\n",
    "links_p_max_pu = links_p_max_pu[base_year].unstack(2)\n",
    "links_p_max_pu = links_p_max_pu.iloc[:len(snapshots)]\n",
    "links_p_max_pu.index = snapshots\n",
    "links.dropna(inplace=True)\n",
    "links_p_max_pu.dropna(axis=1, inplace=True)\n",
    "links[\"carrier\"] = [i[-2:] for i in links.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1750180/862999074.py:139: FutureWarning:\n",
      "\n",
      "DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "\n",
      "/tmp/ipykernel_1750180/862999074.py:13: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1750180/862999074.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demand, links = group_luxembourg(demand, links)\n",
    "\n",
    "commodity_prices = prepare_commodity_prices(commodity_prices_raw[commodity_prices_raw.apply(lambda row: row.astype(str).str.contains(\"ERAA 2025 post-CfE\").any(), axis=1)])\n",
    "\n",
    "dispatchable_plants = pd.read_hdf(\"resources/dispatchable_capacities.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1750180/4291473729.py:13: FutureWarning:\n",
      "\n",
      "DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "\n",
      "/tmp/ipykernel_1750180/4291473729.py:14: FutureWarning:\n",
      "\n",
      "The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = pypsa.Network()\n",
    "n.set_snapshots(snapshots)\n",
    "\n",
    "capacity=pd.read_hdf(\"resources/investcap.h5\")[base_year].unstack(1)\n",
    "\n",
    "buses = (\n",
    "    capacity.sum()[capacity.abs().sum() >0].index\n",
    "    .union(demand.columns)\n",
    "    .union(links.bus0.unique())\n",
    "    .union(links.bus1.unique())\n",
    ")\n",
    "\n",
    "pd.Series(buses).to_csv('buses.csv', index=False)\n",
    "\n",
    "n.add(\n",
    "    \"Bus\", \n",
    "    buses, \n",
    "    carrier = \"electricity\", \n",
    "    country = buses.str[:2]\n",
    ")\n",
    "\n",
    "n.add(\n",
    "    \"Load\", \n",
    "    demand.columns,\n",
    "    bus=demand.columns,\n",
    "    p_set = demand\n",
    ")\n",
    "\n",
    "inflows = build_inflows(inflows_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_c = all_cap.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARKET_NODE             AL00       AT00       BA00     BE00       BG00  \\\n",
      "PEMMDB_PLANT_TYPE                                                        \n",
      "PHS                      0.0        0.0        0.0  10000.0    10000.0   \n",
      "PHS Open                 0.0  1750000.0        0.0      0.0   390000.0   \n",
      "pondage                  0.0    10000.0        0.0      0.0        0.0   \n",
      "hydro              1720000.0   800000.0  1750000.0      0.0  1990000.0   \n",
      "\n",
      "MARKET_NODE             CH00  CZ00      DE00        ES00       FI00  ...  \\\n",
      "PEMMDB_PLANT_TYPE                                                    ...   \n",
      "PHS                  60000.0   0.0  600000.0    170000.0        0.0  ...   \n",
      "PHS Open           1190000.0   0.0  440000.0   5840000.0        0.0  ...   \n",
      "pondage                  0.0   0.0       0.0         0.0        0.0  ...   \n",
      "hydro              8910000.0   0.0  240000.0  13340000.0  5530000.0  ...   \n",
      "\n",
      "MARKET_NODE            RS00        SE01        SE02       SE03     SE04  SI00  \\\n",
      "PEMMDB_PLANT_TYPE                                                               \n",
      "PHS                250000.0         0.0         0.0        0.0      0.0   0.0   \n",
      "PHS Open                0.0         0.0         0.0        0.0      0.0   0.0   \n",
      "pondage                 0.0         0.0         0.0        0.0      0.0   0.0   \n",
      "hydro              650000.0  14430000.0  14800000.0  2640000.0  70000.0   0.0   \n",
      "\n",
      "MARKET_NODE           SK00  TR00  UA00     UK00  \n",
      "PEMMDB_PLANT_TYPE                                \n",
      "PHS                    0.0   0.0   0.0  20000.0  \n",
      "PHS Open           50000.0   0.0   0.0      0.0  \n",
      "pondage            10000.0   0.0   0.0      0.0  \n",
      "hydro              20000.0   0.0   0.0      0.0  \n",
      "\n",
      "[4 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "#def add_existing_storage(all_c):  \n",
    "\n",
    "\n",
    "hydro = pd.read_csv(\"data/Dashboard_raw_data/Hydro additional information.csv\",header=0)\n",
    "\n",
    "all_c = all_c.reset_index(name=\"Value\")\n",
    "\n",
    "closest_year = all_c.loc[(all_c['Target year'] - base_year).abs().idxmin(), 'Target year']\n",
    "\n",
    "all_cy = all_c[all_c['Target year'] == closest_year]\n",
    "\n",
    "#all_cy.to_csv('all_cy.csv', index=False)\n",
    "\n",
    "all_cdata = (all_cy\n",
    "  .pivot(index=\"Technology\", columns=\"Market_Node\", values=all_cy.columns[-1]) \n",
    "  )\n",
    "\n",
    "storage = all_cdata.loc[[\"PHS\",\"PHS Open\",\"hydro\",\"pondage\",\"battery\"]].unstack().reset_index().copy()\n",
    "storage.columns = [\"bus\", \"carrier\", \"p_nom\"]\n",
    "storage.index = storage.bus + \" \" + storage.carrier\n",
    "\n",
    "hydro = hydro[hydro.apply(lambda row: row.astype(str).str.contains(\"ERAA 2025 pre-CfE\").any(), axis=1)]\n",
    "#hydro.to_csv('hydro.csv', index=False)\n",
    "\n",
    "\n",
    "target_year = hydro.loc[hydro[\"TARGET_YEAR\"].sub(base_year).abs().idxmin(), \"TARGET_YEAR\"]\n",
    "hydro_y = hydro[hydro[\"TARGET_YEAR\"] == target_year]\n",
    "\n",
    "#hydro_y.to_csv('hydroyear.csv', index=False)\n",
    "\n",
    "hydro_pump = -(\n",
    "hydro_y.loc[\n",
    "    hydro_y[\"PEMMDB_PLANT_TYPE\"].isin([\"Closed loop pumping\", \"Open loop pumping\"])\n",
    "]\n",
    ".pivot(index=\"PEMMDB_PLANT_TYPE\", columns=\"MARKET_NODE\", values=\"MAX PUMPING CAP (MW)\")\n",
    ".fillna(0)\n",
    ".rename(index={\n",
    "    \"Closed loop pumping\": \"PHS\",\n",
    "    \"Open loop pumping\": \"PHS Open\"\n",
    "})\n",
    ")\n",
    "\n",
    "hydro_pump=hydro_pump.drop(columns=[\"UA00\"], errors='ignore').loc[:, (hydro_pump != 0).any(axis=0)]\n",
    "#hydro_pump.to_csv('hydrostorage.csv', index=False)      \n",
    "\n",
    "hydro_cap=all_cdata.loc[all_cdata.index.isin([\"PHS\", \"PHS Open\"])]\n",
    "\n",
    "#hydro_cap.loc[:, hydro_cap.notna().any(axis=0)].to_csv('hydrocapacity.csv', index=False)\n",
    "\n",
    "p_min_pu = hydro_pump.div(hydro_cap.loc[:, hydro_cap.notna().any(axis=0)].add(1e-5).values).fillna(0)\n",
    "p_min_pu.index = [\"PHS\", \"PHS Open\"]\n",
    "\n",
    "p_min_pu.to_csv('p_min_pu.csv', index=False)\n",
    "\n",
    "valid_countries = p_min_pu.columns[(p_min_pu != 0).any(axis=0)]\n",
    "p_min_pu_filtered = p_min_pu[valid_countries]\n",
    "p_min_pu_stacked = p_min_pu_filtered.stack().fillna(0)  # MultiIndex: (carrier, bus)\n",
    "storage_index = pd.MultiIndex.from_arrays([storage.carrier, storage.bus])\n",
    "storage[\"p_min_pu\"] = p_min_pu_stacked.reindex(storage_index).values \n",
    "\n",
    "#storage.to_csv('storage.csv', index=False)\n",
    "\n",
    "storage.loc[storage.carrier==\"battery\", \"p_min_pu\"] = -1\n",
    "storage.loc[storage.carrier==\"hydro\", \"p_min_pu\"] = 0\n",
    "storage.loc[storage.carrier==\"pondage\", \"p_min_pu\"] = 0\n",
    "\n",
    "storage = storage[storage.p_nom >0]\n",
    "\n",
    "#storage.to_csv('storage.csv', index=False)\n",
    "\n",
    "storage_inflows = inflows[storage.loc[storage.carrier==\"PHS Open\"].index]\n",
    "\n",
    "#storage_inflows .to_csv('storage_inflows0.csv', index=False)\n",
    "\n",
    "storage_inflows = pd.concat([storage_inflows,inflows[storage.loc[storage.carrier == \"hydro\"].index]],axis=1)\n",
    "storage_inflows = pd.concat([storage_inflows,inflows[storage.loc[storage.carrier == \"pondage\"].index]],axis=1)\n",
    "\n",
    "storage_inflows.to_csv('storage_inflows.csv', index=False)\n",
    "\n",
    "hydro_stored = 1000000*(hydro_y.loc[hydro_y[\"PEMMDB_PLANT_TYPE\"].isin([\"Closed loop pumping\", \"Open loop pumping\", \"Reservoir\", \"Pondage\"])]\n",
    "  .pivot(index=\"PEMMDB_PLANT_TYPE\", columns=\"MARKET_NODE\", values=\"Storage Capacity [TWh]\")\n",
    "  .fillna(0)\n",
    "  .rename(index={\n",
    "      \"Closed loop pumping\": \"PHS\",\n",
    "      \"Open loop pumping\": \"PHS Open\",\n",
    "      \"Reservoir\": \"hydro\",\n",
    "      \"Pondage\": \"pondage\"                    \n",
    "  })\n",
    ")       \n",
    "  \n",
    "battery = pd.read_csv(\"data/Dashboard_raw_data/Batteries additional information.csv\",header=0)\n",
    "battery = battery[battery.apply(lambda row: row.astype(str).str.contains(\"ERAA 2025 pre-CfE\").any(), axis=1)]\n",
    "battery.to_csv('battery.csv', index=False)\n",
    "\n",
    "battery_y = battery[battery[\"TARGET_YEAR\"] == base_year]\n",
    "\n",
    "battery_y.to_csv('battery_y.csv', index=False)\n",
    "\n",
    "battery_by_node = battery_y.groupby(\"MARKET_NODE\")[\"STORAGE CAPACITY (MWh)\"].sum().reset_index()\n",
    "\n",
    "battery_by_node.to_csv('battery_y.csv', index=False)\n",
    "battery_by_node[\"Technology\"] = \"battery\"\n",
    "battery_pivot = battery_by_node.pivot(index=\"Technology\", columns=\"MARKET_NODE\", values=\"STORAGE CAPACITY (MWh)\").fillna(0)\n",
    "\n",
    "battery_pivot.to_csv('battery_pivot.csv', index=False)\n",
    "\n",
    "storage_capacity=pd.concat([hydro_stored, battery_pivot])\n",
    "\n",
    "storage_capacity.to_csv('storage_capacity.csv', index=False)\n",
    "  \n",
    "valid_countries = storage_capacity.columns[(storage_capacity != 0).any(axis=0)]\n",
    "stored_filtered = storage_capacity[valid_countries]\n",
    "    \n",
    "stored_stacked = stored_filtered.stack() \n",
    "\n",
    "storage_index = pd.MultiIndex.from_arrays([storage.carrier, storage.bus])\n",
    "\n",
    "#Data in #.## TWh, so 5000 MWh as minimum\n",
    "storage[\"max_hours\"] = stored_stacked.reindex(storage_index).clip(lower=5000).div(storage.p_nom.values).values \n",
    "   \n",
    "map_storage = pd.Series( [\"battery inverter\", \"PHS\", \"hydro\",\"hydro\",\"hydro\"], [\"battery\", \"PHS\", \"PHS Open\",\"hydro\",\"pondage\"])\n",
    "\n",
    "storage[\"efficiency_store\"] = technology_data.loc[:, \"efficiency\", :].reindex(storage.carrier.map(map_storage)).value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    n.add(\n",
    "        \"StorageUnit\",\n",
    "        storage.index,\n",
    "        **storage,\n",
    "        inflow=storage_inflows.reindex(storage.index, axis=1, fill_value=0.),\n",
    "        invest_status = \"existing\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1749889/4291473729.py:13: FutureWarning:\n",
      "\n",
      "DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "\n",
      "/tmp/ipykernel_1749889/4291473729.py:14: FutureWarning:\n",
      "\n",
      "The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARKET_NODE             AL00       AT00       BA00     BE00       BG00  \\\n",
      "PEMMDB_PLANT_TYPE                                                        \n",
      "PHS                      0.0        0.0        0.0  10000.0    10000.0   \n",
      "PHS Open                 0.0  1750000.0        0.0      0.0   390000.0   \n",
      "pondage                  0.0    10000.0        0.0      0.0        0.0   \n",
      "hydro              1720000.0   800000.0  1750000.0      0.0  1990000.0   \n",
      "\n",
      "MARKET_NODE             CH00  CZ00      DE00        ES00       FI00  ...  \\\n",
      "PEMMDB_PLANT_TYPE                                                    ...   \n",
      "PHS                  60000.0   0.0  600000.0    170000.0        0.0  ...   \n",
      "PHS Open           1190000.0   0.0  440000.0   5840000.0        0.0  ...   \n",
      "pondage                  0.0   0.0       0.0         0.0        0.0  ...   \n",
      "hydro              8910000.0   0.0  240000.0  13340000.0  5530000.0  ...   \n",
      "\n",
      "MARKET_NODE            RS00        SE01        SE02       SE03     SE04  SI00  \\\n",
      "PEMMDB_PLANT_TYPE                                                               \n",
      "PHS                250000.0         0.0         0.0        0.0      0.0   0.0   \n",
      "PHS Open                0.0         0.0         0.0        0.0      0.0   0.0   \n",
      "pondage                 0.0         0.0         0.0        0.0      0.0   0.0   \n",
      "hydro              650000.0  14430000.0  14800000.0  2640000.0  70000.0   0.0   \n",
      "\n",
      "MARKET_NODE           SK00  TR00  UA00     UK00  \n",
      "PEMMDB_PLANT_TYPE                                \n",
      "PHS                    0.0   0.0   0.0  20000.0  \n",
      "PHS Open           50000.0   0.0   0.0      0.0  \n",
      "pondage            10000.0   0.0   0.0      0.0  \n",
      "hydro              20000.0   0.0   0.0      0.0  \n",
      "\n",
      "[4 rows x 44 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame inflow has an index which does not align with the passed names.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     22\u001b[39m n.add(\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLoad\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     24\u001b[39m     demand.columns,\n\u001b[32m     25\u001b[39m     bus=demand.columns,\n\u001b[32m     26\u001b[39m     p_set = demand\n\u001b[32m     27\u001b[39m )\n\u001b[32m     29\u001b[39m inflows = build_inflows(inflows_raw)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43madd_existing_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_cap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m add_dispatchables()\n\u001b[32m     35\u001b[39m add_renewables()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 129\u001b[39m, in \u001b[36madd_existing_storage\u001b[39m\u001b[34m(all_c)\u001b[39m\n\u001b[32m    125\u001b[39m storage[\u001b[33m\"\u001b[39m\u001b[33mefficiency_store\u001b[39m\u001b[33m\"\u001b[39m] = technology_data.loc[:, \u001b[33m\"\u001b[39m\u001b[33mefficiency\u001b[39m\u001b[33m\"\u001b[39m, :].reindex(storage.carrier.map(map_storage)).value.values\n\u001b[32m    127\u001b[39m storage.to_csv(\u001b[33m'\u001b[39m\u001b[33mstorage.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStorageUnit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43minflow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_inflows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43minvest_status\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexisting\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/open_eraa/lib/python3.12/site-packages/pypsa/network/transform.py:276\u001b[39m, in \u001b[36mNetworkTransformMixin.add\u001b[39m\u001b[34m(self, class_name, name, suffix, overwrite, return_names, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg.format(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataFrame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnetwork snapshots\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v.columns.equals(names):\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg.format(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataFrame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, names_str))\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# Convert list-like and 1-dim array to pandas.Series\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_1d_list_like(v):\n",
      "\u001b[31mValueError\u001b[39m: DataFrame inflow has an index which does not align with the passed names."
     ]
    }
   ],
   "source": [
    "add_existing_storage(all_cap)\n",
    "\n",
    "add_dispatchables()\n",
    "\n",
    "add_renewables()\n",
    "\n",
    "add_dsr()\n",
    "\n",
    "set_investment_bounds()\n",
    "\n",
    "n.add(\n",
    "    \"Link\",\n",
    "    links.index,\n",
    "    bus0 = links.bus0,\n",
    "    bus1 = links.bus1,\n",
    "    p_nom = links.p_nom,\n",
    "    p_max_pu = links_p_max_pu,\n",
    "    carrier = links.carrier,\n",
    ")\n",
    "\n",
    "#n.generators.loc[(n.generators.bus == \"CY00\") & (n.generators.carrier == \"CCGT\"), \"p_min_pu\"] = 0 # remove minimum load of CCGT in Cyprus as this can exceed actual load.\n",
    "\n",
    "dirname = os.path.dirname(save_path)  \n",
    "\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)\n",
    "\n",
    "#n.export_to_netcdf(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_prices_raw = pd.read_excel(\"data/Fuel and CO2 prices_ERAA2023.xlsx\", index_col = 0)\n",
    "\n",
    "year = 2029\n",
    "\n",
    "climate_year = 1990\n",
    "\n",
    "years = range(2025, 2034)\n",
    "\n",
    "save_path = \"resources/networks/base/cy\" + str(climate_year) + \"_ty\" + str(year) + \".nc\"\n",
    "\n",
    "biomass_price = 7 # make adjustable in config\n",
    "\n",
    "inflows_raw = pd.read_hdf(\"resources/inflow.h5\", \"inflow\")\n",
    "\n",
    "excel_file = pd.ExcelFile(\"data/pemmdb.xlsx\")\n",
    "\n",
    "snapshots = pd.date_range(start=\"2010-01-01\", freq=\"h\", periods=8760)\n",
    "\n",
    "plant_sheets = [i for i in excel_file.sheet_names if \"TY\" in i]\n",
    "plant_sheets = pd.Series([int(i[2:]) for i in plant_sheets], plant_sheets )\n",
    "\n",
    "sheet = plant_sheets[plant_sheets <= year].subtract(year).idxmax()\n",
    "\n",
    "base_year = int(sheet[2:])\n",
    "\n",
    "distributed_resources = [\"onwind\", \"offwind\", \"CSP\",\"solar\", \"battery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_hdf(\"resources/demand.h5\")\n",
    "demand = demand.loc[:, climate_year, :, str(base_year), :].unstack(1)\n",
    "demand.index = snapshots\n",
    "demand.drop(\"TR00\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_hdf(\"resources/ntcs.h5\", \"p_nom\")\n",
    "links_p_max_pu = pd.read_hdf(\"resources/ntcs.h5\", \"p_max_pu\")\n",
    "links = links[base_year].unstack(1)\n",
    "links_p_max_pu = links_p_max_pu[base_year].unstack(2)\n",
    "links_p_max_pu.index = snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.dropna(inplace=True)\n",
    "links_p_max_pu.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[\"carrier\"] = [i[-2:] for i in links.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, links = group_luxembourg(demand, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_prices = prepare_commodity_prices(commodity_prices_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatchable_plants = pd.read_hdf(\"resources/dispatchable_capacities.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_data = pd.read_csv(\"../technology-data/outputs/costs_2025.csv\", index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pypsa.Network()\n",
    "n.set_snapshots(snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = build_capacity_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nom_dsr = pd.read_excel(excel_file, \"Explicit DSR\", index_col = [0,1]).iloc[:, :8]\n",
    "marginal_cost_dsr = pd.read_excel(excel_file, \"Explicit DSR\", index_col = [0,1]).iloc[:, 8:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "buses = (\n",
    "    capacity.sum()[capacity.sum() >0].index\n",
    "    .union(demand.columns)\n",
    "    .union(links.bus0.unique())\n",
    "    .union(links.bus1.unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AL00', 'AT00', 'BA00', 'BE00', 'BEOF', 'BG00', 'CH00', 'CY00', 'CZ00',\n",
       "       'DE00', 'DEKF', 'DKBH', 'DKE1', 'DKKF', 'DKW1', 'EE00', 'ES00', 'FI00',\n",
       "       'FR00', 'GR00', 'GR03', 'HR00', 'HU00', 'IE00', 'ITCA', 'ITCN', 'ITCS',\n",
       "       'ITN1', 'ITS1', 'ITSA', 'ITSI', 'ITVI', 'LT00', 'LUG1', 'LV00', 'ME00',\n",
       "       'MK00', 'MT00', 'NL00', 'NLLL', 'NOM1', 'NON1', 'NOS0', 'PL00', 'PLE0',\n",
       "       'PLI0', 'PT00', 'RO00', 'RS00', 'SE01', 'SE02', 'SE03', 'SE04', 'SI00',\n",
       "       'SK00', 'UK00', 'UKNI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.madd(\n",
    "    \"Bus\", \n",
    "    buses, \n",
    "    carrier = \"electricity\", \n",
    "    country = buses.str[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AL00', 'AT00', 'BA00', 'BE00', 'BG00', 'CH00', 'CY00', 'CZ00', 'DE00',\n",
       "       'DKE1', 'DKW1', 'EE00', 'ES00', 'FI00', 'FR00', 'GR00', 'GR03', 'HR00',\n",
       "       'HU00', 'IE00', 'ITCA', 'ITCN', 'ITCS', 'ITN1', 'ITS1', 'ITSA', 'ITSI',\n",
       "       'LT00', 'LUG1', 'LV00', 'ME00', 'MK00', 'MT00', 'NL00', 'NOM1', 'NON1',\n",
       "       'NOS0', 'PL00', 'PT00', 'RO00', 'RS00', 'SE01', 'SE02', 'SE03', 'SE04',\n",
       "       'SI00', 'SK00', 'UK00', 'UKNI'],\n",
       "      dtype='object', name='zone')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.madd(\n",
    "    \"Load\", \n",
    "    demand.columns,\n",
    "    bus=demand.columns,\n",
    "    p_set = demand\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflows = build_inflows(inflows_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_existing_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2335640/1052378219.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  plants[\"marginal_cost\"] = (\n"
     ]
    }
   ],
   "source": [
    "add_dispatchables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renewables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_investment_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AL00-GR00-AC', 'AL00-ME00-AC', 'AL00-MK00-AC', 'AL00-RS00-AC',\n",
       "       'AT00-CH00-AC', 'AT00-CZ00-AC', 'AT00-DE00-AC', 'AT00-HU00-AC',\n",
       "       'AT00-ITN1-AC', 'AT00-SI00-AC',\n",
       "       ...\n",
       "       'UK00-BE00-DC', 'UK00-DE00-DC', 'UK00-DKW1-DC', 'UK00-FR00-DC',\n",
       "       'UK00-IE00-DC', 'UK00-NL00-DC', 'UK00-NOS0-DC', 'UK00-UKNI-DC',\n",
       "       'UKNI-IE00-AC', 'UKNI-UK00-DC'],\n",
       "      dtype='object', length=212)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.madd(\n",
    "    \"Link\",\n",
    "    links.index,\n",
    "    bus0 = links.bus0,\n",
    "    bus1 = links.bus1,\n",
    "    p_nom = links.p_nom,\n",
    "    p_max_pu = links_p_max_pu,\n",
    "    carrier = links.carrier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AL00 load-shedding', 'AT00 load-shedding', 'BA00 load-shedding',\n",
       "       'BE00 load-shedding', 'BEOF load-shedding', 'BG00 load-shedding',\n",
       "       'CH00 load-shedding', 'CY00 load-shedding', 'CZ00 load-shedding',\n",
       "       'DE00 load-shedding', 'DEKF load-shedding', 'DKBH load-shedding',\n",
       "       'DKE1 load-shedding', 'DKKF load-shedding', 'DKW1 load-shedding',\n",
       "       'EE00 load-shedding', 'ES00 load-shedding', 'FI00 load-shedding',\n",
       "       'FR00 load-shedding', 'GR00 load-shedding', 'GR03 load-shedding',\n",
       "       'HR00 load-shedding', 'HU00 load-shedding', 'IE00 load-shedding',\n",
       "       'ITCA load-shedding', 'ITCN load-shedding', 'ITCS load-shedding',\n",
       "       'ITN1 load-shedding', 'ITS1 load-shedding', 'ITSA load-shedding',\n",
       "       'ITSI load-shedding', 'ITVI load-shedding', 'LT00 load-shedding',\n",
       "       'LUG1 load-shedding', 'LV00 load-shedding', 'ME00 load-shedding',\n",
       "       'MK00 load-shedding', 'MT00 load-shedding', 'NL00 load-shedding',\n",
       "       'NLLL load-shedding', 'NOM1 load-shedding', 'NON1 load-shedding',\n",
       "       'NOS0 load-shedding', 'PL00 load-shedding', 'PLE0 load-shedding',\n",
       "       'PLI0 load-shedding', 'PT00 load-shedding', 'RO00 load-shedding',\n",
       "       'RS00 load-shedding', 'SE01 load-shedding', 'SE02 load-shedding',\n",
       "       'SE03 load-shedding', 'SE04 load-shedding', 'SI00 load-shedding',\n",
       "       'SK00 load-shedding', 'UK00 load-shedding', 'UKNI load-shedding'],\n",
       "      dtype='object', name='Bus')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.madd(\n",
    "    \"Generator\",\n",
    "    n.buses.index + \" load-shedding\",\n",
    "    carrier = \"load-shedding\",\n",
    "    bus = n.buses.index,\n",
    "    p_nom=1e5,\n",
    "    marginal_cost = 10e3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageUnit\n",
       "AL00 reservoir    1.0\n",
       "AT00 PHS          1.0\n",
       "AT00 reservoir    1.0\n",
       "AT00 battery      1.0\n",
       "BA00 reservoir    1.0\n",
       "                 ... \n",
       "SK00 reservoir    1.0\n",
       "SK00 battery      1.0\n",
       "UK00 PHS          1.0\n",
       "UK00 battery      1.0\n",
       "UKNI battery      1.0\n",
       "Name: efficiency_store, Length: 89, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.storage_units.efficiency_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dirname \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(save_path)  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dirname):\n\u001b[1;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(dirname)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "dirname = os.path.dirname(save_path)  \n",
    "\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n.export_to_netcdf(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.optimize(snapshots=n.snapshots[:24], solver_name=\"highs\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = pypsa.Network(\"resources/networks/0/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_eraa",
   "language": "python",
   "name": "open_eraa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
