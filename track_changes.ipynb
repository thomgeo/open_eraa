{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in glob.glob(\"resources/capacity_tables/*csv\"):\n",
    "    iteration = int(os.path.splitext(os.path.basename(table))[0])\n",
    "    cts[iteration] = pd.read_csv(table, index_col=[0,1]).p_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = cts[range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_existing = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"results/revenue_ratios/*exist*\"):\n",
    "    iteration = int(os.path.basename(file).split(\"_\")[0])\n",
    "    rr_existing[iteration] = pd.read_csv(file, index_col=0).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_existing.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rr_existing = rr_existing[range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_existing = rr_existing[cts.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining = rr_existing[cts.loc[rr_existing.index, cts.columns[-1]] > 0.01].dropna(how=\"all\").index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic = cts.loc[remaining][cts.loc[remaining, 0] != cts.loc[remaining, cts.columns[-1]]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITN1 OCGT exit 2034  2025   -5.0\n",
       "                     2027   -5.0\n",
       "                     2026   -5.0\n",
       "ITCA CCGT exit 2034  2027   -3.0\n",
       "                     2025   -3.0\n",
       "                     2026   -3.0\n",
       "ITN1 CCGT exit 2034  2026   -3.0\n",
       "ITCS CCGT exit 2034  2025   -1.0\n",
       "ITN1 CCGT exit 2034  2027   -1.0\n",
       "                     2025   -1.0\n",
       "ITCS CCGT exit 2034  2026   -1.0\n",
       "                     2027    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_existing.loc[dynamic].clip(upper=1, lower=-1).iloc[:, 3:].sum(axis=1).sort_values().filter(like=\"IT\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator                \n",
       "RO00 CCGT exit 2034  2027    0.785714\n",
       "                     2025    0.785714\n",
       "                     2026    0.785714\n",
       "GR00 CCGT exit 2034  2025    0.738095\n",
       "ITCS CCGT exit 2034  2026    0.738095\n",
       "                     2027    0.738095\n",
       "PL00 coal exit 2034  2027    0.738095\n",
       "                     2026    0.738095\n",
       "                     2025    0.738095\n",
       "GR00 CCGT exit 2034  2027    0.738095\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts.loc[dynamic].diff(axis=1).iloc[:, 4:].sum(axis=1).div(\n",
    "    cts.loc[dynamic].diff(axis=1).iloc[:, 4:].abs().sum(axis=1)\n",
    "\n",
    ").sort_values(ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator                \n",
       "BE00 CCGT exit 2034  2027      0.0\n",
       "                     2025      0.0\n",
       "                     2026      0.0\n",
       "AT00 CCGT exit 2034  2025    150.0\n",
       "UKNI oil exit 2034   2025    350.0\n",
       "                             ...  \n",
       "UKNI OCGT exit 2034  2025    350.0\n",
       "                     2026    350.0\n",
       "UK00 OCGT exit 2034  2025    350.0\n",
       "                     2026    350.0\n",
       "                     2027    350.0\n",
       "Length: 87, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts.loc[dynamic].diff(axis=1).iloc[:, 7:].abs().sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator                \n",
       "DE00 CCGT exit 2034  2025   -1.000000\n",
       "ES00 CCGT exit 2034  2025   -1.000000\n",
       "DE00 CCGT exit 2034  2027   -1.000000\n",
       "                     2026   -1.000000\n",
       "ES00 CCGT exit 2034  2026   -1.000000\n",
       "                               ...   \n",
       "AT00 CCGT exit 2028  2025    0.142857\n",
       "UKNI CCGT exit 2034  2027    0.285714\n",
       "                     2025    0.285714\n",
       "                     2026    0.285714\n",
       "UK00 CCGT exit 2028  2025    0.285714\n",
       "Length: 87, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts.loc[dynamic].diff(axis=1).iloc[:, 7:].sum(axis=1).div(\n",
    "    cts.loc[dynamic].diff(axis=1).iloc[:, 7:].abs().sum(axis=1).add(1e-6)\n",
    ").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant = \"DE00 CCGT exit 2034\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_negs = rr_existing.loc[dynamic, range(4, rr_existing.columns[-1])].max(axis=1)[rr_existing.loc[dynamic, range(4,  rr_existing.columns[-1])].max(axis=1)<0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE00 CCGT exit 2034</th>\n",
       "      <th>2025</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>-2000.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES00 CCGT exit 2034</th>\n",
       "      <th>2025</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>-2000.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>-2000.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>-2000.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ITN1 CCGT exit 2034</th>\n",
       "      <th>2025</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>-250.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0       1       2       3      4      5      6   \\\n",
       "Generator                                                                   \n",
       "DE00 CCGT exit 2034 2025 NaN -4000.0 -2000.0 -1000.0 -500.0 -250.0 -125.0   \n",
       "ES00 CCGT exit 2034 2025 NaN -4000.0 -2000.0 -1000.0 -500.0 -250.0 -125.0   \n",
       "                    2026 NaN -4000.0 -2000.0 -1000.0 -500.0 -250.0 -125.0   \n",
       "                    2027 NaN -4000.0 -2000.0 -1000.0 -500.0 -250.0 -125.0   \n",
       "ITN1 CCGT exit 2034 2025 NaN -4000.0  2000.0 -1000.0 -500.0 -250.0 -125.0   \n",
       "                    2026 NaN -4000.0  2000.0 -1000.0 -500.0 -250.0 -125.0   \n",
       "\n",
       "                            7     8     9     10    11    12    13    14  \n",
       "Generator                                                                 \n",
       "DE00 CCGT exit 2034 2025 -75.0  75.0 -75.0 -75.0 -75.0 -75.0  75.0 -75.0  \n",
       "ES00 CCGT exit 2034 2025 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0  \n",
       "                    2026 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0  \n",
       "                    2027 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0 -75.0  \n",
       "ITN1 CCGT exit 2034 2025 -75.0 -75.0 -75.0  75.0 -75.0 -75.0  75.0 -75.0  \n",
       "                    2026 -75.0 -75.0 -75.0  75.0 -75.0 -75.0  75.0 -75.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts.loc[all_negs].diff(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cts.loc[dynamic].sum().loc[35:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE00 CCGT exit 2034</th>\n",
       "      <th>2025</th>\n",
       "      <td>-11659.866285</td>\n",
       "      <td>-587.594489</td>\n",
       "      <td>-7348.662761</td>\n",
       "      <td>-369.145106</td>\n",
       "      <td>-600.292012</td>\n",
       "      <td>-4264.536349</td>\n",
       "      <td>-497.349675</td>\n",
       "      <td>-1546.968801</td>\n",
       "      <td>-2461.211652</td>\n",
       "      <td>-434.167382</td>\n",
       "      <td>-514.868706</td>\n",
       "      <td>-3757.245912</td>\n",
       "      <td>-2434.685943</td>\n",
       "      <td>-2494.786234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES00 CCGT exit 2034</th>\n",
       "      <th>2025</th>\n",
       "      <td>-5696.310279</td>\n",
       "      <td>-7510.699775</td>\n",
       "      <td>-6839.331017</td>\n",
       "      <td>-6075.530634</td>\n",
       "      <td>-6157.741376</td>\n",
       "      <td>-6019.228491</td>\n",
       "      <td>-5936.063755</td>\n",
       "      <td>-5920.446803</td>\n",
       "      <td>-5913.303610</td>\n",
       "      <td>-5861.105536</td>\n",
       "      <td>-5796.331357</td>\n",
       "      <td>-5619.146536</td>\n",
       "      <td>-5792.830249</td>\n",
       "      <td>-5738.942692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>-8206.913915</td>\n",
       "      <td>-7811.346947</td>\n",
       "      <td>-6936.851529</td>\n",
       "      <td>-6313.242928</td>\n",
       "      <td>-6231.468027</td>\n",
       "      <td>-6012.091718</td>\n",
       "      <td>-6027.652478</td>\n",
       "      <td>-5991.224525</td>\n",
       "      <td>-5988.614155</td>\n",
       "      <td>-5944.561244</td>\n",
       "      <td>-5874.524471</td>\n",
       "      <td>-3479.267484</td>\n",
       "      <td>-5835.942173</td>\n",
       "      <td>-5800.441366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>-9042.146130</td>\n",
       "      <td>-7908.625946</td>\n",
       "      <td>-6957.705922</td>\n",
       "      <td>-6396.143898</td>\n",
       "      <td>-6266.928782</td>\n",
       "      <td>-6092.054832</td>\n",
       "      <td>-6073.543772</td>\n",
       "      <td>-6030.578853</td>\n",
       "      <td>-6002.036767</td>\n",
       "      <td>-5961.551556</td>\n",
       "      <td>-5901.672821</td>\n",
       "      <td>-4215.957946</td>\n",
       "      <td>-1616.905519</td>\n",
       "      <td>-5823.164123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ITN1 CCGT exit 2034</th>\n",
       "      <th>2025</th>\n",
       "      <td>-8701.024502</td>\n",
       "      <td>6251.095939</td>\n",
       "      <td>-5259.349906</td>\n",
       "      <td>-2165.085256</td>\n",
       "      <td>-3357.143991</td>\n",
       "      <td>-4072.107035</td>\n",
       "      <td>-4048.564326</td>\n",
       "      <td>-3738.918273</td>\n",
       "      <td>-928.014916</td>\n",
       "      <td>-3972.600314</td>\n",
       "      <td>-3193.216423</td>\n",
       "      <td>-2559.050059</td>\n",
       "      <td>-3315.069617</td>\n",
       "      <td>-3333.506998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>-8739.635927</td>\n",
       "      <td>2458.501682</td>\n",
       "      <td>-5294.194906</td>\n",
       "      <td>-3346.347338</td>\n",
       "      <td>-3284.870834</td>\n",
       "      <td>-3496.763253</td>\n",
       "      <td>-3793.334292</td>\n",
       "      <td>-3787.015374</td>\n",
       "      <td>-2533.804213</td>\n",
       "      <td>-3459.244705</td>\n",
       "      <td>-3649.093027</td>\n",
       "      <td>-1297.293316</td>\n",
       "      <td>-3670.200727</td>\n",
       "      <td>-3714.852208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    1            2            3            4   \\\n",
       "DE00 CCGT exit 2034 2025 -11659.866285  -587.594489 -7348.662761  -369.145106   \n",
       "ES00 CCGT exit 2034 2025  -5696.310279 -7510.699775 -6839.331017 -6075.530634   \n",
       "                    2026  -8206.913915 -7811.346947 -6936.851529 -6313.242928   \n",
       "                    2027  -9042.146130 -7908.625946 -6957.705922 -6396.143898   \n",
       "ITN1 CCGT exit 2034 2025  -8701.024502  6251.095939 -5259.349906 -2165.085256   \n",
       "                    2026  -8739.635927  2458.501682 -5294.194906 -3346.347338   \n",
       "\n",
       "                                   5            6            7            8   \\\n",
       "DE00 CCGT exit 2034 2025  -600.292012 -4264.536349  -497.349675 -1546.968801   \n",
       "ES00 CCGT exit 2034 2025 -6157.741376 -6019.228491 -5936.063755 -5920.446803   \n",
       "                    2026 -6231.468027 -6012.091718 -6027.652478 -5991.224525   \n",
       "                    2027 -6266.928782 -6092.054832 -6073.543772 -6030.578853   \n",
       "ITN1 CCGT exit 2034 2025 -3357.143991 -4072.107035 -4048.564326 -3738.918273   \n",
       "                    2026 -3284.870834 -3496.763253 -3793.334292 -3787.015374   \n",
       "\n",
       "                                   9            10           11           12  \\\n",
       "DE00 CCGT exit 2034 2025 -2461.211652  -434.167382  -514.868706 -3757.245912   \n",
       "ES00 CCGT exit 2034 2025 -5913.303610 -5861.105536 -5796.331357 -5619.146536   \n",
       "                    2026 -5988.614155 -5944.561244 -5874.524471 -3479.267484   \n",
       "                    2027 -6002.036767 -5961.551556 -5901.672821 -4215.957946   \n",
       "ITN1 CCGT exit 2034 2025  -928.014916 -3972.600314 -3193.216423 -2559.050059   \n",
       "                    2026 -2533.804213 -3459.244705 -3649.093027 -1297.293316   \n",
       "\n",
       "                                   13           14  \n",
       "DE00 CCGT exit 2034 2025 -2434.685943 -2494.786234  \n",
       "ES00 CCGT exit 2034 2025 -5792.830249 -5738.942692  \n",
       "                    2026 -5835.942173 -5800.441366  \n",
       "                    2027 -1616.905519 -5823.164123  \n",
       "ITN1 CCGT exit 2034 2025 -3315.069617 -3333.506998  \n",
       "                    2026 -3670.200727 -3714.852208  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_existing.loc[all_negs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"results/revenue_ratios/*new*\"):\n",
    "    iteration = int(os.path.basename(file).split(\"_\")[0])\n",
    "    rr_new[iteration] = pd.read_csv(file, index_col=0)[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_new.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lole = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n",
      "/tmp/ipykernel_3339297/4057654764.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"results/lole/**/*\"):\n",
    "\n",
    "    iteration = file.split(\"/\")[2]\n",
    "    climate_year = file.split(\"cy\")[1][:4]\n",
    "    target_year = file.split(\"ty\")[1][:4]\n",
    "    lole[\" \".join([target_year, climate_year, iteration])] = pd.read_csv(file, index_col=0)[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lole = lole.T.set_index([[i.split(\" \")[j] for i in lole.columns] for j in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lole.index = lole.index.set_levels(lole.index.levels[0].astype(int), level=0)\n",
    "lole.index = lole.index.set_levels(lole.index.levels[1].astype(int), level=1)\n",
    "lole.index = lole.index.set_levels(lole.index.levels[2].astype(int), level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lole.columns = lole.columns.str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Generator</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AT00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.4</td>\n",
       "      <td>42.6</td>\n",
       "      <td>47.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.4</td>\n",
       "      <td>13.8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.6</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.6</td>\n",
       "      <td>12.8</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.6</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Generator  AT00            \n",
       "           2025  2026  2027\n",
       "0           0.0   0.0   0.0\n",
       "1          54.4  42.6  47.4\n",
       "2          11.0   9.0  14.4\n",
       "3           7.2   6.0  14.2\n",
       "4           7.4  11.4  14.2\n",
       "5          14.6  14.8  14.0\n",
       "6           8.4  13.8   8.0\n",
       "7           9.0   6.4  13.6\n",
       "8          10.6  10.4   8.2\n",
       "9           9.8   8.6  12.4\n",
       "10         11.0  12.2   8.2\n",
       "11          9.4  11.8  11.6\n",
       "12         12.8  10.6  11.8\n",
       "13         10.8  13.2  16.6\n",
       "14          8.6  12.8   9.4\n",
       "15          9.2  11.6   9.4\n",
       "16         10.2  11.8   9.2\n",
       "17          6.2  12.0   7.6\n",
       "18          9.6  11.8  11.4\n",
       "19         13.2  13.4   8.4\n",
       "20         13.4  11.2  11.6\n",
       "21         12.6   9.6   7.8\n",
       "22         12.2  11.8   8.0\n",
       "23         12.2  12.0  12.6\n",
       "24          9.8  10.6   7.6\n",
       "25          9.2   9.0   8.0\n",
       "26          9.0  10.8  13.6\n",
       "27          5.2  10.2   9.4\n",
       "28          8.2   9.6   8.0\n",
       "29         17.8  15.0   8.2\n",
       "30         15.2   9.6   9.0\n",
       "31         10.2  13.8  10.6\n",
       "32          8.6  14.2   9.2\n",
       "33         13.2   8.6  11.4\n",
       "34          9.8  10.2  10.4\n",
       "35          9.4   9.8   9.2\n",
       "37          0.2   0.6   0.0\n",
       "38          4.8   4.4   0.0\n",
       "39          0.0   0.6   0.6\n",
       "40          0.0   0.0   0.6\n",
       "41          4.4   0.0   5.0\n",
       "42          4.0   0.8   0.2\n",
       "43          0.0   0.0   0.6\n",
       "44          4.8   0.4   0.8\n",
       "45          0.4   0.0   0.0\n",
       "46          0.0   0.4   0.0\n",
       "47          0.4   0.0   0.0\n",
       "48          0.4   0.0   0.2\n",
       "49          1.0   0.0   1.2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lole.groupby(level=[0,2]).mean().filter(like=\"AT\").unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>capacity_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration  capacity_change\n",
       "0          1.0             8000\n",
       "1          2.0             4000\n",
       "2          3.0             2000\n",
       "3          4.0             1000\n",
       "4          5.0              500\n",
       "..         ...              ...\n",
       "146      147.0               75\n",
       "147      148.0               75\n",
       "148      149.0               75\n",
       "149      150.0               75\n",
       "150        NaN               75\n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/capacity_adjustement_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lole.groupby(level=[2]).mean().loc[20:30].DE00.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = \"DE00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 CCGT exit 2033</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 CCGT exit 2034</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 OCGT exit 2033</th>\n",
       "      <th>DE00 OCGT exit 2034</th>\n",
       "      <th>...</th>\n",
       "      <th>DE00 lignite exit 2030</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 oil exit 2028</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 oil exit 2033</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 oil exit 2034</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>...</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.063275</td>\n",
       "      <td>-0.064780</td>\n",
       "      <td>-0.065322</td>\n",
       "      <td>-4987.600139</td>\n",
       "      <td>-5693.371117</td>\n",
       "      <td>-5830.512860</td>\n",
       "      <td>-0.273451</td>\n",
       "      <td>-0.277870</td>\n",
       "      <td>-0.279424</td>\n",
       "      <td>-0.273451</td>\n",
       "      <td>...</td>\n",
       "      <td>13308.380643</td>\n",
       "      <td>-0.288392</td>\n",
       "      <td>-0.293940</td>\n",
       "      <td>-0.295963</td>\n",
       "      <td>-0.288392</td>\n",
       "      <td>-0.293940</td>\n",
       "      <td>-0.295963</td>\n",
       "      <td>-0.288392</td>\n",
       "      <td>-0.293940</td>\n",
       "      <td>-0.295963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.063622</td>\n",
       "      <td>-0.064833</td>\n",
       "      <td>-0.065303</td>\n",
       "      <td>-5445.167808</td>\n",
       "      <td>-5835.520860</td>\n",
       "      <td>-5898.068798</td>\n",
       "      <td>-0.274673</td>\n",
       "      <td>-0.278078</td>\n",
       "      <td>-0.279399</td>\n",
       "      <td>-0.274673</td>\n",
       "      <td>...</td>\n",
       "      <td>13349.721688</td>\n",
       "      <td>-0.289570</td>\n",
       "      <td>-0.294055</td>\n",
       "      <td>-0.295825</td>\n",
       "      <td>-0.289570</td>\n",
       "      <td>-0.294055</td>\n",
       "      <td>-0.295825</td>\n",
       "      <td>-0.289570</td>\n",
       "      <td>-0.294055</td>\n",
       "      <td>-0.295825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.063823</td>\n",
       "      <td>-0.064996</td>\n",
       "      <td>-0.065441</td>\n",
       "      <td>-5917.568691</td>\n",
       "      <td>-5961.873980</td>\n",
       "      <td>-5947.947986</td>\n",
       "      <td>-0.275495</td>\n",
       "      <td>-0.278678</td>\n",
       "      <td>-0.279894</td>\n",
       "      <td>-0.275495</td>\n",
       "      <td>...</td>\n",
       "      <td>13279.324760</td>\n",
       "      <td>-0.290163</td>\n",
       "      <td>-0.294645</td>\n",
       "      <td>-0.296342</td>\n",
       "      <td>-0.290163</td>\n",
       "      <td>-0.294645</td>\n",
       "      <td>-0.296342</td>\n",
       "      <td>-0.290163</td>\n",
       "      <td>-0.294645</td>\n",
       "      <td>-0.296342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.063703</td>\n",
       "      <td>-0.064868</td>\n",
       "      <td>-0.065327</td>\n",
       "      <td>-5707.350059</td>\n",
       "      <td>-5831.296442</td>\n",
       "      <td>-5819.585019</td>\n",
       "      <td>-0.275044</td>\n",
       "      <td>-0.278258</td>\n",
       "      <td>-0.279535</td>\n",
       "      <td>-0.275044</td>\n",
       "      <td>...</td>\n",
       "      <td>13295.763143</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-0.294134</td>\n",
       "      <td>-0.295893</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-0.294134</td>\n",
       "      <td>-0.295893</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-0.294134</td>\n",
       "      <td>-0.295893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.063642</td>\n",
       "      <td>-0.064793</td>\n",
       "      <td>-0.065284</td>\n",
       "      <td>-5482.172875</td>\n",
       "      <td>-5667.794250</td>\n",
       "      <td>-5684.138134</td>\n",
       "      <td>-0.274925</td>\n",
       "      <td>-0.278081</td>\n",
       "      <td>-0.279440</td>\n",
       "      <td>-0.274925</td>\n",
       "      <td>...</td>\n",
       "      <td>13354.655579</td>\n",
       "      <td>-0.289584</td>\n",
       "      <td>-0.293914</td>\n",
       "      <td>-0.295777</td>\n",
       "      <td>-0.289584</td>\n",
       "      <td>-0.293914</td>\n",
       "      <td>-0.295777</td>\n",
       "      <td>-0.289584</td>\n",
       "      <td>-0.293914</td>\n",
       "      <td>-0.295777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.061970</td>\n",
       "      <td>-0.063998</td>\n",
       "      <td>-0.064731</td>\n",
       "      <td>-2737.314178</td>\n",
       "      <td>-4250.786071</td>\n",
       "      <td>-4692.825121</td>\n",
       "      <td>-0.268853</td>\n",
       "      <td>-0.275179</td>\n",
       "      <td>-0.277435</td>\n",
       "      <td>-0.268853</td>\n",
       "      <td>...</td>\n",
       "      <td>13853.283451</td>\n",
       "      <td>-0.283982</td>\n",
       "      <td>-0.291278</td>\n",
       "      <td>-0.293941</td>\n",
       "      <td>-0.283982</td>\n",
       "      <td>-0.291278</td>\n",
       "      <td>-0.293941</td>\n",
       "      <td>-0.283982</td>\n",
       "      <td>-0.291278</td>\n",
       "      <td>-0.293941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.063967</td>\n",
       "      <td>-0.065009</td>\n",
       "      <td>-0.065399</td>\n",
       "      <td>-5566.656446</td>\n",
       "      <td>-5594.682345</td>\n",
       "      <td>-5552.854016</td>\n",
       "      <td>-0.275891</td>\n",
       "      <td>-0.278719</td>\n",
       "      <td>-0.279779</td>\n",
       "      <td>-0.275891</td>\n",
       "      <td>...</td>\n",
       "      <td>13258.894254</td>\n",
       "      <td>-0.290735</td>\n",
       "      <td>-0.294715</td>\n",
       "      <td>-0.296217</td>\n",
       "      <td>-0.290735</td>\n",
       "      <td>-0.294715</td>\n",
       "      <td>-0.296217</td>\n",
       "      <td>-0.290735</td>\n",
       "      <td>-0.294715</td>\n",
       "      <td>-0.296217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.063769</td>\n",
       "      <td>-0.064861</td>\n",
       "      <td>-0.065268</td>\n",
       "      <td>-5379.392948</td>\n",
       "      <td>-5459.061733</td>\n",
       "      <td>-5400.640820</td>\n",
       "      <td>-0.275343</td>\n",
       "      <td>-0.278322</td>\n",
       "      <td>-0.279408</td>\n",
       "      <td>-0.275343</td>\n",
       "      <td>...</td>\n",
       "      <td>13422.934799</td>\n",
       "      <td>-0.290031</td>\n",
       "      <td>-0.294187</td>\n",
       "      <td>-0.295755</td>\n",
       "      <td>-0.290031</td>\n",
       "      <td>-0.294187</td>\n",
       "      <td>-0.295755</td>\n",
       "      <td>-0.290031</td>\n",
       "      <td>-0.294187</td>\n",
       "      <td>-0.295755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.063814</td>\n",
       "      <td>-0.064838</td>\n",
       "      <td>-0.065241</td>\n",
       "      <td>-5294.263623</td>\n",
       "      <td>-5358.332101</td>\n",
       "      <td>-5298.888866</td>\n",
       "      <td>-0.275453</td>\n",
       "      <td>-0.278202</td>\n",
       "      <td>-0.279296</td>\n",
       "      <td>-0.275453</td>\n",
       "      <td>...</td>\n",
       "      <td>13450.343110</td>\n",
       "      <td>-0.290217</td>\n",
       "      <td>-0.294086</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>-0.290217</td>\n",
       "      <td>-0.294086</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>-0.290217</td>\n",
       "      <td>-0.294086</td>\n",
       "      <td>-0.295646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.063599</td>\n",
       "      <td>-0.064587</td>\n",
       "      <td>-0.064992</td>\n",
       "      <td>-4844.830587</td>\n",
       "      <td>-4949.301605</td>\n",
       "      <td>-4912.726915</td>\n",
       "      <td>-0.274698</td>\n",
       "      <td>-0.277338</td>\n",
       "      <td>-0.278428</td>\n",
       "      <td>-0.274698</td>\n",
       "      <td>...</td>\n",
       "      <td>13582.760150</td>\n",
       "      <td>-0.289523</td>\n",
       "      <td>-0.293233</td>\n",
       "      <td>-0.294786</td>\n",
       "      <td>-0.289523</td>\n",
       "      <td>-0.293233</td>\n",
       "      <td>-0.294786</td>\n",
       "      <td>-0.289523</td>\n",
       "      <td>-0.293233</td>\n",
       "      <td>-0.294786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.059153</td>\n",
       "      <td>-0.062604</td>\n",
       "      <td>-0.063676</td>\n",
       "      <td>1850.639424</td>\n",
       "      <td>-1704.526712</td>\n",
       "      <td>-2682.946383</td>\n",
       "      <td>-0.258772</td>\n",
       "      <td>-0.270168</td>\n",
       "      <td>-0.273668</td>\n",
       "      <td>-0.258772</td>\n",
       "      <td>...</td>\n",
       "      <td>14747.932963</td>\n",
       "      <td>-0.274713</td>\n",
       "      <td>-0.286732</td>\n",
       "      <td>-0.290504</td>\n",
       "      <td>-0.274713</td>\n",
       "      <td>-0.286732</td>\n",
       "      <td>-0.290504</td>\n",
       "      <td>-0.274713</td>\n",
       "      <td>-0.286732</td>\n",
       "      <td>-0.290504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DE00 CCGT exit 2033                     DE00 CCGT exit 2034               \\\n",
       "                  2025      2026      2027                2025         2026   \n",
       "20           -0.063275 -0.064780 -0.065322        -4987.600139 -5693.371117   \n",
       "21           -0.063622 -0.064833 -0.065303        -5445.167808 -5835.520860   \n",
       "22           -0.063823 -0.064996 -0.065441        -5917.568691 -5961.873980   \n",
       "23           -0.063703 -0.064868 -0.065327        -5707.350059 -5831.296442   \n",
       "24           -0.063642 -0.064793 -0.065284        -5482.172875 -5667.794250   \n",
       "25           -0.061970 -0.063998 -0.064731        -2737.314178 -4250.786071   \n",
       "26           -0.063967 -0.065009 -0.065399        -5566.656446 -5594.682345   \n",
       "27           -0.063769 -0.064861 -0.065268        -5379.392948 -5459.061733   \n",
       "28           -0.063814 -0.064838 -0.065241        -5294.263623 -5358.332101   \n",
       "29           -0.063599 -0.064587 -0.064992        -4844.830587 -4949.301605   \n",
       "30           -0.059153 -0.062604 -0.063676         1850.639424 -1704.526712   \n",
       "\n",
       "                DE00 OCGT exit 2033                     DE00 OCGT exit 2034  \\\n",
       "           2027                2025      2026      2027                2025   \n",
       "20 -5830.512860           -0.273451 -0.277870 -0.279424           -0.273451   \n",
       "21 -5898.068798           -0.274673 -0.278078 -0.279399           -0.274673   \n",
       "22 -5947.947986           -0.275495 -0.278678 -0.279894           -0.275495   \n",
       "23 -5819.585019           -0.275044 -0.278258 -0.279535           -0.275044   \n",
       "24 -5684.138134           -0.274925 -0.278081 -0.279440           -0.274925   \n",
       "25 -4692.825121           -0.268853 -0.275179 -0.277435           -0.268853   \n",
       "26 -5552.854016           -0.275891 -0.278719 -0.279779           -0.275891   \n",
       "27 -5400.640820           -0.275343 -0.278322 -0.279408           -0.275343   \n",
       "28 -5298.888866           -0.275453 -0.278202 -0.279296           -0.275453   \n",
       "29 -4912.726915           -0.274698 -0.277338 -0.278428           -0.274698   \n",
       "30 -2682.946383           -0.258772 -0.270168 -0.273668           -0.258772   \n",
       "\n",
       "    ... DE00 lignite exit 2030 DE00 oil exit 2028                      \\\n",
       "    ...                   2027               2025      2026      2027   \n",
       "20  ...           13308.380643          -0.288392 -0.293940 -0.295963   \n",
       "21  ...           13349.721688          -0.289570 -0.294055 -0.295825   \n",
       "22  ...           13279.324760          -0.290163 -0.294645 -0.296342   \n",
       "23  ...           13295.763143          -0.289705 -0.294134 -0.295893   \n",
       "24  ...           13354.655579          -0.289584 -0.293914 -0.295777   \n",
       "25  ...           13853.283451          -0.283982 -0.291278 -0.293941   \n",
       "26  ...           13258.894254          -0.290735 -0.294715 -0.296217   \n",
       "27  ...           13422.934799          -0.290031 -0.294187 -0.295755   \n",
       "28  ...           13450.343110          -0.290217 -0.294086 -0.295646   \n",
       "29  ...           13582.760150          -0.289523 -0.293233 -0.294786   \n",
       "30  ...           14747.932963          -0.274713 -0.286732 -0.290504   \n",
       "\n",
       "   DE00 oil exit 2033                     DE00 oil exit 2034            \\\n",
       "                 2025      2026      2027               2025      2026   \n",
       "20          -0.288392 -0.293940 -0.295963          -0.288392 -0.293940   \n",
       "21          -0.289570 -0.294055 -0.295825          -0.289570 -0.294055   \n",
       "22          -0.290163 -0.294645 -0.296342          -0.290163 -0.294645   \n",
       "23          -0.289705 -0.294134 -0.295893          -0.289705 -0.294134   \n",
       "24          -0.289584 -0.293914 -0.295777          -0.289584 -0.293914   \n",
       "25          -0.283982 -0.291278 -0.293941          -0.283982 -0.291278   \n",
       "26          -0.290735 -0.294715 -0.296217          -0.290735 -0.294715   \n",
       "27          -0.290031 -0.294187 -0.295755          -0.290031 -0.294187   \n",
       "28          -0.290217 -0.294086 -0.295646          -0.290217 -0.294086   \n",
       "29          -0.289523 -0.293233 -0.294786          -0.289523 -0.293233   \n",
       "30          -0.274713 -0.286732 -0.290504          -0.274713 -0.286732   \n",
       "\n",
       "              \n",
       "        2027  \n",
       "20 -0.295963  \n",
       "21 -0.295825  \n",
       "22 -0.296342  \n",
       "23 -0.295893  \n",
       "24 -0.295777  \n",
       "25 -0.293941  \n",
       "26 -0.296217  \n",
       "27 -0.295755  \n",
       "28 -0.295646  \n",
       "29 -0.294786  \n",
       "30 -0.290504  \n",
       "\n",
       "[11 rows x 39 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_existing.filter(like=bus, axis=0).loc[:, range(20,31)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Generator</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 CCGT exit 2033</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 CCGT exit 2034</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 OCGT exit 2033</th>\n",
       "      <th>DE00 OCGT exit 2034</th>\n",
       "      <th>...</th>\n",
       "      <th>DE00 lignite exit 2030</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 oil exit 2028</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 oil exit 2033</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE00 oil exit 2034</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>...</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "      <th>2025</th>\n",
       "      <th>2026</th>\n",
       "      <th>2027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-336.041454</td>\n",
       "      <td>-336.041454</td>\n",
       "      <td>-336.041454</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>-83.618546</td>\n",
       "      <td>-83.618546</td>\n",
       "      <td>-83.618546</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-935.99</td>\n",
       "      <td>-935.99</td>\n",
       "      <td>-935.99</td>\n",
       "      <td>-840.49</td>\n",
       "      <td>-840.49</td>\n",
       "      <td>-840.49</td>\n",
       "      <td>-1044.82</td>\n",
       "      <td>-1044.82</td>\n",
       "      <td>-1044.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3023.751344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.256914</td>\n",
       "      <td>79.256914</td>\n",
       "      <td>79.256914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-164.295634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.292595</td>\n",
       "      <td>110.944063</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.745624</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.912174</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>-188.984459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Generator DE00 CCGT exit 2033                         DE00 CCGT exit 2034  \\\n",
       "                         2025        2026        2027                2025   \n",
       "0                         NaN         NaN         NaN                 NaN   \n",
       "1                 -336.041454 -336.041454 -336.041454        -3023.751344   \n",
       "2                    0.000000    0.000000    0.000000        -3023.751344   \n",
       "3                    0.000000    0.000000    0.000000           79.256914   \n",
       "4                    0.000000    0.000000    0.000000         -188.984459   \n",
       "5                    0.000000    0.000000    0.000000         -188.984459   \n",
       "6                    0.000000    0.000000    0.000000         -188.984459   \n",
       "7                    0.000000    0.000000    0.000000         -188.984459   \n",
       "8                    0.000000    0.000000    0.000000         -188.984459   \n",
       "9                    0.000000    0.000000    0.000000          130.292595   \n",
       "10                   0.000000    0.000000    0.000000         -188.984459   \n",
       "11                   0.000000    0.000000    0.000000         -188.984459   \n",
       "12                   0.000000    0.000000    0.000000         -188.984459   \n",
       "13                   0.000000    0.000000    0.000000         -188.984459   \n",
       "14                   0.000000    0.000000    0.000000         -188.984459   \n",
       "15                   0.000000    0.000000    0.000000         -188.984459   \n",
       "16                   0.000000    0.000000    0.000000          105.745624   \n",
       "17                   0.000000    0.000000    0.000000         -188.984459   \n",
       "18                   0.000000    0.000000    0.000000         -188.984459   \n",
       "19                   0.000000    0.000000    0.000000         -188.984459   \n",
       "20                   0.000000    0.000000    0.000000         -188.984459   \n",
       "21                   0.000000    0.000000    0.000000         -188.984459   \n",
       "22                   0.000000    0.000000    0.000000         -188.984459   \n",
       "23                   0.000000    0.000000    0.000000         -188.984459   \n",
       "24                   0.000000    0.000000    0.000000         -188.984459   \n",
       "25                   0.000000    0.000000    0.000000         -188.984459   \n",
       "26                   0.000000    0.000000    0.000000         -188.984459   \n",
       "27                   0.000000    0.000000    0.000000         -188.984459   \n",
       "28                   0.000000    0.000000    0.000000         -188.984459   \n",
       "29                   0.000000    0.000000    0.000000         -188.984459   \n",
       "30                   0.000000    0.000000    0.000000          102.912174   \n",
       "31                   0.000000    0.000000    0.000000         -188.984459   \n",
       "32                   0.000000    0.000000    0.000000         -188.984459   \n",
       "\n",
       "Generator                           DE00 OCGT exit 2033                        \\\n",
       "                  2026         2027                2025       2026       2027   \n",
       "0                  NaN          NaN                 NaN        NaN        NaN   \n",
       "1         -3023.751344 -3023.751344          -83.618546 -83.618546 -83.618546   \n",
       "2         -3023.751344 -3023.751344            0.000000   0.000000   0.000000   \n",
       "3            79.256914    79.256914            0.000000   0.000000   0.000000   \n",
       "4          -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "5          -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "6          -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "7          -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "8          -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "9           110.944063  -188.984459            0.000000   0.000000   0.000000   \n",
       "10         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "11         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "12         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "13         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "14         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "15         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "16         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "17         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "18         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "19         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "20         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "21         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "22         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "23         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "24         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "25         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "26         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "27         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "28         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "29         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "30         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "31         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "32         -188.984459  -188.984459            0.000000   0.000000   0.000000   \n",
       "\n",
       "Generator DE00 OCGT exit 2034  ... DE00 lignite exit 2030 DE00 oil exit 2028  \\\n",
       "                         2025  ...                   2027               2025   \n",
       "0                         NaN  ...                    NaN                NaN   \n",
       "1                -3023.751344  ...                    0.0            -935.99   \n",
       "2                -3023.751344  ...                    0.0               0.00   \n",
       "3                 -188.984459  ...                    0.0               0.00   \n",
       "4                 -164.295634  ...                    0.0               0.00   \n",
       "5                    0.000000  ...                    0.0               0.00   \n",
       "6                    0.000000  ...                    0.0               0.00   \n",
       "7                    0.000000  ...                    0.0               0.00   \n",
       "8                    0.000000  ...                    0.0               0.00   \n",
       "9                    0.000000  ...                    0.0               0.00   \n",
       "10                   0.000000  ...                    0.0               0.00   \n",
       "11                   0.000000  ...                    0.0               0.00   \n",
       "12                   0.000000  ...                    0.0               0.00   \n",
       "13                   0.000000  ...                    0.0               0.00   \n",
       "14                   0.000000  ...                    0.0               0.00   \n",
       "15                   0.000000  ...                    0.0               0.00   \n",
       "16                   0.000000  ...                    0.0               0.00   \n",
       "17                   0.000000  ...                    0.0               0.00   \n",
       "18                   0.000000  ...                    0.0               0.00   \n",
       "19                   0.000000  ...                    0.0               0.00   \n",
       "20                   0.000000  ...                    0.0               0.00   \n",
       "21                   0.000000  ...                    0.0               0.00   \n",
       "22                   0.000000  ...                    0.0               0.00   \n",
       "23                   0.000000  ...                    0.0               0.00   \n",
       "24                   0.000000  ...                    0.0               0.00   \n",
       "25                   0.000000  ...                    0.0               0.00   \n",
       "26                   0.000000  ...                    0.0               0.00   \n",
       "27                   0.000000  ...                    0.0               0.00   \n",
       "28                   0.000000  ...                    0.0               0.00   \n",
       "29                   0.000000  ...                    0.0               0.00   \n",
       "30                   0.000000  ...                    0.0               0.00   \n",
       "31                   0.000000  ...                    0.0               0.00   \n",
       "32                   0.000000  ...                    0.0               0.00   \n",
       "\n",
       "Generator                 DE00 oil exit 2033                  \\\n",
       "             2026    2027               2025    2026    2027   \n",
       "0             NaN     NaN                NaN     NaN     NaN   \n",
       "1         -935.99 -935.99            -840.49 -840.49 -840.49   \n",
       "2            0.00    0.00               0.00    0.00    0.00   \n",
       "3            0.00    0.00               0.00    0.00    0.00   \n",
       "4            0.00    0.00               0.00    0.00    0.00   \n",
       "5            0.00    0.00               0.00    0.00    0.00   \n",
       "6            0.00    0.00               0.00    0.00    0.00   \n",
       "7            0.00    0.00               0.00    0.00    0.00   \n",
       "8            0.00    0.00               0.00    0.00    0.00   \n",
       "9            0.00    0.00               0.00    0.00    0.00   \n",
       "10           0.00    0.00               0.00    0.00    0.00   \n",
       "11           0.00    0.00               0.00    0.00    0.00   \n",
       "12           0.00    0.00               0.00    0.00    0.00   \n",
       "13           0.00    0.00               0.00    0.00    0.00   \n",
       "14           0.00    0.00               0.00    0.00    0.00   \n",
       "15           0.00    0.00               0.00    0.00    0.00   \n",
       "16           0.00    0.00               0.00    0.00    0.00   \n",
       "17           0.00    0.00               0.00    0.00    0.00   \n",
       "18           0.00    0.00               0.00    0.00    0.00   \n",
       "19           0.00    0.00               0.00    0.00    0.00   \n",
       "20           0.00    0.00               0.00    0.00    0.00   \n",
       "21           0.00    0.00               0.00    0.00    0.00   \n",
       "22           0.00    0.00               0.00    0.00    0.00   \n",
       "23           0.00    0.00               0.00    0.00    0.00   \n",
       "24           0.00    0.00               0.00    0.00    0.00   \n",
       "25           0.00    0.00               0.00    0.00    0.00   \n",
       "26           0.00    0.00               0.00    0.00    0.00   \n",
       "27           0.00    0.00               0.00    0.00    0.00   \n",
       "28           0.00    0.00               0.00    0.00    0.00   \n",
       "29           0.00    0.00               0.00    0.00    0.00   \n",
       "30           0.00    0.00               0.00    0.00    0.00   \n",
       "31           0.00    0.00               0.00    0.00    0.00   \n",
       "32           0.00    0.00               0.00    0.00    0.00   \n",
       "\n",
       "Generator DE00 oil exit 2034                    \n",
       "                        2025     2026     2027  \n",
       "0                        NaN      NaN      NaN  \n",
       "1                   -1044.82 -1044.82 -1044.82  \n",
       "2                       0.00     0.00     0.00  \n",
       "3                       0.00     0.00     0.00  \n",
       "4                       0.00     0.00     0.00  \n",
       "5                       0.00     0.00     0.00  \n",
       "6                       0.00     0.00     0.00  \n",
       "7                       0.00     0.00     0.00  \n",
       "8                       0.00     0.00     0.00  \n",
       "9                       0.00     0.00     0.00  \n",
       "10                      0.00     0.00     0.00  \n",
       "11                      0.00     0.00     0.00  \n",
       "12                      0.00     0.00     0.00  \n",
       "13                      0.00     0.00     0.00  \n",
       "14                      0.00     0.00     0.00  \n",
       "15                      0.00     0.00     0.00  \n",
       "16                      0.00     0.00     0.00  \n",
       "17                      0.00     0.00     0.00  \n",
       "18                      0.00     0.00     0.00  \n",
       "19                      0.00     0.00     0.00  \n",
       "20                      0.00     0.00     0.00  \n",
       "21                      0.00     0.00     0.00  \n",
       "22                      0.00     0.00     0.00  \n",
       "23                      0.00     0.00     0.00  \n",
       "24                      0.00     0.00     0.00  \n",
       "25                      0.00     0.00     0.00  \n",
       "26                      0.00     0.00     0.00  \n",
       "27                      0.00     0.00     0.00  \n",
       "28                      0.00     0.00     0.00  \n",
       "29                      0.00     0.00     0.00  \n",
       "30                      0.00     0.00     0.00  \n",
       "31                      0.00     0.00     0.00  \n",
       "32                      0.00     0.00     0.00  \n",
       "\n",
       "[33 rows x 39 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts.loc[rr_existing.filter(like=\"DE00\", axis=0).index, range(0,33)].T.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_hdf(\"resources/demand.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = \"DE00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_year = 1982\n",
    "target_year = 2033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-805.7545425379454"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand.loc[:, climate_year, zone, str(target_year)].sort_values(ascending = False).diff().iloc[:10].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-training",
   "language": "python",
   "name": "pypsa-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
